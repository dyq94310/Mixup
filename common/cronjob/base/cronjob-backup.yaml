apiVersion: batch/v1
kind: CronJob
metadata:
  name: k3s-backup-placeholder
  namespace: common
  annotations:
    reloader.stakater.com/auto: "true"
spec:
  # 每天凌晨 4 点执行 (Cron 表达式: 分 时 日 月 周)
  schedule: "0 4 * * *"
  # 如果上一个任务没跑完，不启动新的，避免堆积
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      template:
        spec:
          # --- 关键控制点：指定在该节点运行 ---
          # 方式 A: 直接指定节点名
          # nodeName: "YOUR_NODE_NAME_HERE"
          
          # 方式 B: 或者使用标签选择 (二选一，如果用了 nodeName 就不需要这个)
          nodeSelector:
            kubernetes.io/hostname: "placeholder"

          restartPolicy: OnFailure
          
          # 容忍度：确保能在 Master 节点上运行
          tolerations:
          - effect: NoSchedule
            operator: Exists
          - key: CriticalAddonsOnly
            operator: Exists

          containers:
          - name: backup-worker
            image: rclone/rclone:v1.72-stable
            command: ["/bin/sh", "-c"]
            args:
              - |
                set -e
                set -o pipefail

                echo "[$(date)] 开始双重备份任务..."
                
                DATE=$(date +%Y%m%d)
                FILE_NAME="k3s-data-${MY_NODE_NAME}-${DATE}.tar.gz"
                
                # 定义两个目的地
                DEST_RUSTFS="mys3:${S3_BUCKET}/backups/${MY_NODE_NAME}/${FILE_NAME}"
                DEST_R2="cfr2:${R2_BUCKET}/backups/${MY_NODE_NAME}/${FILE_NAME}"

                # 1. 备份到 RustFS (本地)
                echo "正在上传至 RustFS: $DEST_RUSTFS"
                tar -cz -C /host-data --exclude='rustfs*' . | rclone rcat "$DEST_RUSTFS"

                # 2. 备份到 Cloudflare R2 (远程)
                # 重新运行一次 tar。虽然多花一点 CPU，但比在容器内存里缓存整个压缩包安全
                echo "正在上传至 Cloudflare R2: $DEST_R2"
                tar -cz -C /host-data --exclude='rustfs*' . | rclone rcat "$DEST_R2"

                echo "所有上传成功。"

                # 3. 清理逻辑 (两边都保留 10 天)
                echo "正在清理旧备份..."
                rclone delete "mys3:${S3_BUCKET}/backups/${MY_NODE_NAME}/" --min-age 10d
                rclone delete "cfr2:${R2_BUCKET}/backups/${MY_NODE_NAME}/" --min-age 10d
                
                echo "[$(date)] 任务顺利完成。"
            env:
            - name: MY_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            
            # --- Rclone 环境变量配置 (代替 rclone.conf) ---
            - name: RCLONE_CONFIG_MYS3_TYPE
              value: "s3"
            - name: RCLONE_CONFIG_MYS3_PROVIDER
              value: "Other"
              
            - name: RCLONE_CONFIG_MYS3_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: common-secret-config
                  key: RCLONE_CONFIG_MYS3_ACCESS_KEY_ID
            - name: RCLONE_CONFIG_MYS3_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: common-secret-config
                  key: RCLONE_CONFIG_MYS3_SECRET_ACCESS_KEY

            - name: RCLONE_CONFIG_MYS3_ENDPOINT
              value: "http://rustfs-svc.rustfs.svc.cluster.local:9000"
            - name: RCLONE_CONFIG_MYS3_ACL
              value: "private"

            - name: S3_BUCKET
              value: "k3s-bk"

              # --- 新增的 Cloudflare R2 配置 ---
            - name: RCLONE_CONFIG_CFR2_TYPE
              value: "s3"
            - name: RCLONE_CONFIG_CFR2_PROVIDER
              value: "Cloudflare"
            - name: RCLONE_CONFIG_CFR2_NO_CHECK_BUCKET
              value: "true"
            - name: RCLONE_CONFIG_CFR2_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: common-secret-config
                  key: RCLONE_CONFIG_CFR2_ACCESS_KEY_ID
            - name: RCLONE_CONFIG_CFR2_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: common-secret-config
                  key: RCLONE_CONFIG_CFR2_SECRET_ACCESS_KEY
            - name: RCLONE_CONFIG_CFR2_ENDPOINT
              value: "https://df9ea185b64531a1d64cf67c3bdc8209.r2.cloudflarestorage.com"
            - name: R2_BUCKET
              value: "k3s-backup" # 你在 CF 创建的 Bucket 名字

              
            volumeMounts:
            - name: k3s-data
              mountPath: /host-data
              readOnly: true
          
          volumes:
          - name: k3s-data
            hostPath:
              path: /opt/k3s-data
              type: Directory